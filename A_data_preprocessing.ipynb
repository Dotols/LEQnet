{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# import os\n",
    "# import datetime\n",
    "# from tqdm.notebook import tqdm\n",
    "# from obspy import read\n",
    "# import h5py\n",
    "# import csv\n",
    "# import json\n",
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# import multiprocessing\n",
    "# from multiprocessing.pool import ThreadPool\n",
    "\n",
    "# os.getpid()\n",
    "\n",
    "# def process(station_name, overlap=0.3):\n",
    "\n",
    "#     # ex) /home/volume/workspace/Project/Earthquake/data/mseed_data/PH05\n",
    "#     DIR = os.getcwd()\n",
    "#     data_path = os.path.join(DIR, 'data/mseed_data')\n",
    "#     station_path = os.path.join(data_path, station_name)    \n",
    "#     mseed_list = os.listdir(station_path)\n",
    "#     mseed_dict = dict()\n",
    "\n",
    "#     for mseed in tqdm(mseed_list):\n",
    "#         # ex) /home/volume/workspace/Project/Earthquake/data/mseed_data/PH05/PH.PH05.00.BHE__20180226T000000Z__20180227T000000Z.mseed\n",
    "#         file_path = os.path.join(station_path, mseed)\n",
    "#         # ex) PH.PH05.00.BHE__20180226T000000Z__20180227T000000Z.mseed\n",
    "#         file_name = mseed\n",
    "#         # ex) PH.PH05.00.20180226T000000Z__20180227T000000Z.mseed\n",
    "#         file_name_st = mseed[:11] + mseed[16:32]\n",
    "#         # ex) E or N or Z\n",
    "#         axis = file_path.split('.')[3].split('__')[0][2]\n",
    "\n",
    "#         st = read(file_path)\n",
    "\n",
    "#         if file_name_st not in mseed_dict.keys():\n",
    "#             mseed_dict[file_name_st] = dict()\n",
    " \n",
    "#         mseed_dict[file_name_st][axis] = {\n",
    "#             'file_name' : file_name,\n",
    "#             'mseed' : st\n",
    "#         }\n",
    "    \n",
    "#     data = mseed_dict    \n",
    "    \n",
    "#     json_station = json.load(open(os.path.join(os.getcwd(),\"json/PH_station.json\")))\n",
    "#     output_name = list(data.keys())[0].split('.')[1]\n",
    "    \n",
    "#     try:\n",
    "#         os.remove(os.path.join(DIR, 'preprocessed_data/' + output_name + '.hdf5'))\n",
    "#         os.remove(os.path.join(DIR, 'preprocessed_data/' + output_name + '.csv'))\n",
    "#     except Exception:\n",
    "#         pass\n",
    "    \n",
    "#     HDF = h5py.File(os.path.join(DIR, 'preprocessed_data/' + output_name + '.hdf5'), 'a')\n",
    "#     HDF.create_group(\"data\")\n",
    "    \n",
    "#     slide_estimates = list()\n",
    "#     csvfile = open(os.path.join(DIR, 'preprocessed_data/' + output_name + '.csv'), 'w')\n",
    "#     output_writer = csv.writer(csvfile, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "#     output_writer.writerow(['trace_name', 'start_time'])\n",
    "#     csvfile.flush()     \n",
    "\n",
    "#     for mseed in tqdm(data.keys()):\n",
    "#         st = data[mseed]['E']['mseed'].copy()\n",
    "#         st2 = data[mseed]['N']['mseed'].copy()\n",
    "#         st3 = data[mseed]['Z']['mseed'].copy()\n",
    "        \n",
    "#         st.detrend('demean')\n",
    "#         st2.detrend('demean')\n",
    "#         st3.detrend('demean')\n",
    "        \n",
    "        \n",
    "#         st.append(st2[0])\n",
    "#         st.append(st3[0])\n",
    "        \n",
    "#         st.filter('bandpass', freqmin = 1.0, freqmax = 45, corners=2, zerophase=True)\n",
    "        \n",
    "#         st.taper(max_percentage=0.001, type='cosine', max_length=2)\n",
    "        \n",
    "#         org_samplingRate = st[0].stats.sampling_rate\n",
    "#         longest = st[0].stats.npts\n",
    "#         start_time = st[0].stats.starttime\n",
    "#         end_time = st[0].stats.endtime\n",
    "#         tim_shift = int(60-(overlap*60))\n",
    "            \n",
    "#         for tt in st:\n",
    "#             if tt.stats.npts > longest:\n",
    "#                 longest = tt.stats.npts\n",
    "#                 start_time = tt.stats.starttime\n",
    "#                 end_time = tt.stats.endtime\n",
    "#         st.trim(start_time, end_time, pad = True, fill_value=0)\n",
    "#         slide_estimates.append((end_time - start_time)//tim_shift)\n",
    "        \n",
    "#         chanL = [st[0].stats.channel[-1], st[1].stats.channel[-1], st[2].stats.channel[-1]]\n",
    "#         next_slice = start_time + 60\n",
    "        \n",
    "#         while next_slice <= end_time:\n",
    "#             w=st.slice(start_time, next_slice)\n",
    "#             npz_data = np.zeros([12000, 3])\n",
    "            \n",
    "#             npz_data[:, 0] = w[chanL.index('E')].data[:12000]\n",
    "#             npz_data[:, 1] = w[chanL.index('N')].data[:12000]\n",
    "#             npz_data[:, 2] = w[chanL.index('Z')].data[:12000]\n",
    "            \n",
    "#             tr_name = st[0].stats.station + '_' + st[0].stats.network + '_' + \\\n",
    "#                       st[0].stats.channel[:2] + '_' + str(start_time)\n",
    "#             start_time_str = str(start_time).replace('T', ' ').replace('Z', '')\n",
    "                \n",
    "#             HDF = h5py.File(os.path.join(DIR, 'preprocessed_data/'+ output_name +'.hdf5'), 'r')\n",
    "#             dsF = HDF.create_dataset('data/'+tr_name, npz_data.shape, data = npz_data, dtype= np.float32)\n",
    "#             dsF.attrs[\"trace_name\"] = tr_name\n",
    "#             dsF.attrs[\"receiver_code\"] = output_name\n",
    "#             dsF.attrs[\"network_code\"] = json_station[output_name]['network']\n",
    "#             dsF.attrs[\"receiver_latitude\"] = json_station[output_name]['coords'][0]\n",
    "#             dsF.attrs[\"receiver_longitude\"] = json_station[output_name]['coords'][1]\n",
    "#             dsF.attrs[\"receiver_elevation_m\"] = json_station[output_name]['coords'][2]\n",
    "#             dsF.attrs['trace_start_time'] = start_time_str\n",
    "            \n",
    "#             output_writer.writerow([str(tr_name), start_time_str])  \n",
    "            \n",
    "#             HDF.flush()\n",
    "#             csvfile.flush()\n",
    "            \n",
    "#             start_time = start_time + tim_shift\n",
    "#             next_slice = next_slice + tim_shift \n",
    "            \n",
    "# #             break\n",
    "# #         break\n",
    "    \n",
    "#         st1, st2, st3 = None, None, None\n",
    "                \n",
    "#     HDF.close() \n",
    "#     dd = pd.read_csv(os.path.join(DIR, 'preprocessed_data/' + output_name+\".csv\"))\n",
    "    \n",
    "#     return 1\n",
    "\n",
    "# def preprocess(station_num, cpu=16):\n",
    "\n",
    "#     DIR = os.getcwd()\n",
    "#     data_path = os.path.join(DIR, 'data/mseed_data')\n",
    "#     station_list = sorted(os.listdir(data_path))[:station_num]\n",
    "    \n",
    "#     n_processor = multiprocessing.cpu_count()\n",
    "    \n",
    "#     print('available cpu count : ', n_processor)\n",
    "#     print('select cpu count : ', cpu)\n",
    "    \n",
    "#     with ThreadPool(cpu) as p:\n",
    "#         p.map(process, station_list)\n",
    "    \n",
    "#     return 1\n",
    "# preprocess(1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19848\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ac2b8620e67496da630f8df03099d16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=15.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import datetime\n",
    "from tqdm.notebook import tqdm\n",
    "from obspy import read\n",
    "\n",
    "import h5py\n",
    "import csv\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "import multiprocessing\n",
    "from multiprocessing.pool import ThreadPool\n",
    "import gc\n",
    "\n",
    "print(os.getpid())\n",
    "\n",
    "DIR = os.getcwd()\n",
    "data_path = os.path.join(DIR, 'data/mseed_data')\n",
    "\n",
    "station_list = sorted(os.listdir(data_path))\n",
    "\n",
    "data_tree = dict()\n",
    "\n",
    "for station_name in tqdm(station_list):\n",
    "    station_path = os.path.join(data_path, station_name)\n",
    "    mseed_list = os.listdir(station_path)\n",
    "    data_tree[station_name] = dict()\n",
    "    \n",
    "    for mseed in mseed_list:\n",
    "        mseed_group = mseed[:11] + mseed[16:32]\n",
    "        if mseed_group not in data_tree[station_name].keys():\n",
    "            data_tree[station_name][mseed_group] = list()\n",
    "        \n",
    "        data_tree[station_name][mseed_group].append(mseed)\n",
    "        \n",
    "for station_name in data_tree.keys():\n",
    "    for mseed_group in sorted(data_tree[station_name].keys()):\n",
    "        if len(data_tree[station_name][mseed_group]) != 3:\n",
    "            data_tree[station_name].pop(mseed_group)\n",
    "            \n",
    "del station_name, station_path, mseed, mseed_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PH01\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "713f4d088984464a8f1365347abe1869",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found  20171115\n",
      "found  20171115\n",
      "\n",
      "PH02\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cfa4cb586802427a921f9f811639745a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found  20171115\n",
      "\n",
      "PH03\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0cf83642640f45669cf52dd27683d161",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found  20171115\n",
      "found  20171115\n",
      "\n",
      "PH04\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57e1fdc7b54546acbd32ddc8e17033ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found  20171115\n",
      "found  20171115\n",
      "\n",
      "PH05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c41ac2634e4d4666a2d6fdc54289f3b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found  20171115\n",
      "found  20171115\n",
      "\n",
      "PH06\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa4abf2b7e5d4e42abec5137b875696e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found  20171115\n",
      "found  20171115\n",
      "\n",
      "PH07\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8ae6d785f91420a83a60b310f2a42bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found  20171115\n",
      "found  20171115\n",
      "\n",
      "PH08\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "753d54a5edd7429c8ed86d85d95cb45d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found  20171115\n",
      "found  20171115\n",
      "\n",
      "PH09\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0225075eda9443908b4731ac8466429f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found  20171115\n",
      "found  20171115\n",
      "\n",
      "PH10\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d99c9b0fcffb42dba8f5509c52c45e5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found  20171115\n",
      "\n",
      "PH11\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c017e36cea6342d7be56efe93dcff8a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "PH12\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1cbf941bb7fb4bd7886ece0efaa42543",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "PH13\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f446a8efb8d4b17bdeb42ab054edb2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[ Top 10 ]\n",
      "<ipython-input-3-098e1d5bbe1a>:46: size=226 MiB, count=4938, average=46.9 KiB\n",
      "<__array_function__ internals>:6: size=58.5 MiB, count=29, average=2065 KiB\n",
      "/usr/local/lib/python3.6/dist-packages/scipy/fft/_pocketfft/basic.py:251: size=29.2 MiB, count=2, average=14.6 MiB\n",
      "<frozen importlib._bootstrap_external>:487: size=3050 KiB, count=28003, average=112 B\n",
      "<ipython-input-3-098e1d5bbe1a>:64: size=484 KiB, count=1647, average=301 B\n",
      "<ipython-input-3-098e1d5bbe1a>:93: size=394 KiB, count=5857, average=69 B\n",
      "/usr/lib/python3.6/email/feedparser.py:469: size=214 KiB, count=24, average=9112 B\n",
      "/usr/local/lib/python3.6/dist-packages/obspy/core/utcdatetime.py:1056: size=187 KiB, count=1994, average=96 B\n",
      "/usr/local/lib/python3.6/dist-packages/obspy/core/util/attribdict.py:67: size=152 KiB, count=2159, average=72 B\n",
      "/usr/lib/python3.6/_strptime.py:576: size=129 KiB, count=3292, average=40 B\n"
     ]
    }
   ],
   "source": [
    "import tracemalloc\n",
    "\n",
    "tracemalloc.start()\n",
    "\n",
    "# ... run your application ...\n",
    "\n",
    "def preprocessing(file_list, window_size=6000, overlap=0.3):\n",
    "    preprocessed_data = list()\n",
    "    for file in file_list:\n",
    "        file_path = os.path.join(data_path, file[3:7], file)\n",
    "        if file.split('__')[0][-1] == 'E':\n",
    "            st1 = read(file_path)\n",
    "        if file.split('__')[0][-1] == 'N':\n",
    "            st2 = read(file_path)\n",
    "        if file.split('__')[0][-1] == 'Z':\n",
    "            st3 = read(file_path)\n",
    "            \n",
    "        \n",
    "    st1.detrend('demean')\n",
    "    st2.detrend('demean')\n",
    "    st3.detrend('demean')\n",
    "    st1.append(st2[0])\n",
    "    st1.append(st3[0])\n",
    "\n",
    "    st1.filter('bandpass', freqmin = 1.0, freqmax = 45, corners=2, zerophase=True)\n",
    "    st1.resample(100)\n",
    "    st1.taper(max_percentage=0.001, type='cosine', max_length=2)\n",
    "\n",
    "    org_samplingRate = st1[0].stats.sampling_rate\n",
    "    longest = st1[0].stats.npts\n",
    "    start_time = st1[0].stats.starttime\n",
    "    end_time = st1[0].stats.endtime\n",
    "\n",
    "    for tt in st1:\n",
    "        if tt.stats.npts > longest:\n",
    "            longest = tt.stats.npts\n",
    "            start_time = tt.stats.starttime\n",
    "            end_time = tt.stats.endtime\n",
    "    st1.trim(start_time, end_time, pad = True, fill_value=0)\n",
    "\n",
    "    next_slice = start_time + 60\n",
    "    tim_shift = int(60-(overlap*60))\n",
    "\n",
    "    while next_slice <= end_time:\n",
    "        w=st1.slice(start_time, next_slice)\n",
    "        npz_data = np.zeros([window_size, 3])\n",
    "\n",
    "        npz_data[:, 0] = w[0].data[:window_size]\n",
    "        npz_data[:, 1] = w[1].data[:window_size]\n",
    "        npz_data[:, 2] = w[2].data[:window_size]\n",
    "\n",
    "        \n",
    "        tr_name = st1[0].stats.station + '_' + st1[0].stats.network + '_' + \\\n",
    "                  st1[0].stats.channel[:2] + '_' + str(start_time)\n",
    "        start_time_str = str(start_time).replace('T', ' ').replace('Z', '')\n",
    "\n",
    "        preprocessed_data.append({\n",
    "            'trace_start_time': datetime.datetime.strptime(str(start_time), \"%Y-%m-%dT%H:%M:%S.%fZ\"),\n",
    "            'trace_end_time': datetime.datetime.strptime(str(next_slice), \"%Y-%m-%dT%H:%M:%S.%fZ\"),\n",
    "            'data': npz_data,\n",
    "            'p_arv': None,\n",
    "            's_arv': None,\n",
    "            'p_label': 0,\n",
    "            's_label': 0\n",
    "        })\n",
    "        \n",
    "        start_time = start_time + tim_shift\n",
    "        next_slice = next_slice + tim_shift\n",
    "    \n",
    "    return preprocessed_data\n",
    "    \n",
    "for station_name in list(data_tree.keys())[:13]:\n",
    "    print(station_name)\n",
    "    dir_path = os.path.join(DIR, 'data/preprocessed_data', station_name)\n",
    "    \n",
    "    if not os.path.isdir(dir_path):\n",
    "        os.mkdir(dir_path)\n",
    "        \n",
    "    mseed_groups = sorted(list(data_tree[station_name].keys()))\n",
    "    \n",
    "    \n",
    "    for idx, mseed_group in tqdm(enumerate(mseed_groups)):\n",
    "        if mseed_group[11:19] != '20171115':\n",
    "            continue\n",
    "            \n",
    "        print('found ', mseed_group[11:19])\n",
    "        preprocessed_data = list()\n",
    "            \n",
    "        data = preprocessing(data_tree[station_name][mseed_group]).copy()\n",
    "        preprocessed_data = preprocessed_data.copy() + data.copy()\n",
    "        \n",
    "        with open(os.path.join(dir_path, '{}.pkl'.format(mseed_group)), 'wb') as f:\n",
    "            pickle.dump(preprocessed_data, f)\n",
    "            \n",
    "        if idx == 10:\n",
    "            break\n",
    "\n",
    "# ... finish application ...\n",
    "snapshot = tracemalloc.take_snapshot()\n",
    "top_stats = snapshot.statistics('lineno')\n",
    "\n",
    "print(\"[ Top 10 ]\")\n",
    "for stat in top_stats[:10]:\n",
    "    print(stat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

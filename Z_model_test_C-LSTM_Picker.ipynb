{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# # class weighted_BCE(nn.Module):\n",
    "# #     def __init__(self, weights=None):\n",
    "# #         self.weights = weights\n",
    "        \n",
    "# #     def forward(self, out, target):\n",
    "# #         output = torch.clamp(output,min=1e-7,max=1-1e-7)\n",
    "# #         bce = - self.weights[1] * target * torch.log(output) - (1 - target) * self.weights[0] * torch.log(1 - output)\n",
    "        \n",
    "# #         return torch.mean(bce)\n",
    "\n",
    "\n",
    "# def train(dataset, h_params):\n",
    "# #     global cnn_encoder\n",
    "# #     global lstm_decoder\n",
    "# #     global cnn_decoder\n",
    "# #     global criterion\n",
    "    \n",
    "#     epochs = h_params['epochs']\n",
    "#     batch_size = dataset['batch_size']\n",
    "#     total_step = dataset['train_size']//batch_size\n",
    "    \n",
    "#     # Loss\n",
    "# #     loss_fn = weighted_BCE(weights=[1, 12000])\n",
    "    \n",
    "# #     cnn_encoder = CNNEncoder(h_params['inp_size'], h_params['kernel_size'], h_params['embed_size']).to(DEVICE)\n",
    "# #     lstm_decoder = RNNDecoder(h_params['lstm_cell_count'], h_params['embed_size'], h_params['hidden_size']).to(DEVICE)\n",
    "# #     cnn_decoder = CNNDecoder(h_params['inp_size'], h_params['kernel_size'], h_params['embed_size']).to(DEVICE)\n",
    "#     c_lstm = C_LSTM(h_params)\n",
    "# #     criterion = nn.BCELoss(reduction='sum')\n",
    "    \n",
    "#     params = list(c_lstm.parameters())\n",
    "#     optimizer = torch.optim.Adam(params, lr=h_params['lr'])\n",
    "\n",
    "#     plot_dict = dict()\n",
    "#     losses = list()\n",
    "#     val_losses = list()\n",
    "#     acc = list()\n",
    "#     prec = list() \n",
    "#     rec = list()\n",
    "#     f1 = list()\n",
    "\n",
    "#     t0 = time.time()\n",
    "    \n",
    "#     for epoch in range(1, epochs+1):\n",
    "\n",
    "#         for i_step in range(1, total_step+1):\n",
    "# #             c_lstm.cnn_encoder.train()\n",
    "# #             c_lstm.lstm_decoder.train()\n",
    "# #             c_lstm.cnn_decoder.train()\n",
    "            \n",
    "# #             c_lstm.cnn_encoder.zero_grad()\n",
    "# #             c_lstm.lstm_decoder.zero_grad()\n",
    "# #             c_lstm.cnn_decoder.zero_grad()\n",
    "            \n",
    "#             c_lstm.train()\n",
    "#             c_lstm.zero_grad()\n",
    "#             c_lstm.eval()\n",
    "# #             optimizer.zero_grad()\n",
    "\n",
    "#             inps, labels = next(iter(dataset['train_loader']))\n",
    "            \n",
    "#             outps = c_lstm(inps)\n",
    "#             labels = labels.to(DEVICE)\n",
    "            \n",
    "#             loss = weighted_BCE(outps[:,:,:], labels[:,:,:], weights=[1, 12000])\n",
    "# #             loss = loss_fn(outps[:,:,:], labels[:,:,:])\n",
    "            \n",
    "#             loss.backward()\n",
    "#             optimizer.step()\n",
    "\n",
    "#             # - - - Validate - - -\n",
    "#             with torch.no_grad():\n",
    "\n",
    "# #                 c_lstm.cnn_encoder.eval()\n",
    "# #                 c_lstm.lstm_decoder.eval()\n",
    "# #                 c_lstm.cnn_decoder.eval()\n",
    "#                 c_lstm.eval()\n",
    "\n",
    "#                 val_inps, val_labels = next(iter(dataset['valid_loader']))\n",
    "\n",
    "#                 val_outps = c_lstm(val_inps)\n",
    "#                 val_labels = val_labels.to(DEVICE)\n",
    "#     #                 print(np.unique(val_labels[0,:,:].to('cpu').numpy()))\n",
    "\n",
    "#                 val_loss = weighted_BCE(val_outps[:,:,:], val_labels[:,:,:], weights=[1, 12000])\n",
    "#     #             val_loss = loss_fn(val_outps[:,:,:], val_labels[:,:,:])\n",
    "\n",
    "#                 val_accuracy, val_precision, val_recall, val_F1_score, TP, FP, TN, FN = 0, 0, 0, 0, 0, 0, 0, 0\n",
    "#     #                 val_accuracy, val_precision, val_recall, val_F1_score, TP, FP, TN, FN = metric(val_outps, val_labels)\n",
    "                \n",
    "#             val_losses.append(val_loss.item())\n",
    "#             losses.append(loss.item())\n",
    "#             acc.append(val_accuracy)\n",
    "#             prec.append(val_precision)\n",
    "#             rec.append(val_recall)\n",
    "#             f1.append(val_F1_score)\n",
    "            \n",
    "#             stats_loss = 'Epoch [%d/%d], Step [%d/%d], Loss: %.4f, Val Loss: %.4f, ' % \\\n",
    "#                         (epoch, epochs, i_step, total_step, loss.item(), val_loss.item())\n",
    "#             stats_metric = 'accuracy : %.4f, precision : %.4f, recall : %.4f, F1_score : %.4f, ' % \\\n",
    "#                             (val_accuracy, val_precision, val_recall, val_F1_score)\n",
    "#             stats_conf = 'TP : %d, FP : %d, TN : %d, FN : %d' % (TP, FP, TN, FN)\n",
    "#             stats = stats_loss + stats_metric + stats_conf\n",
    "# #             print('\\r', stats, end=\"\")\n",
    "#             print('\\r', stats_loss, end=\"\")\n",
    "\n",
    "# #         print('\\r', stats)\n",
    "#         print('\\r', stats_loss)\n",
    "\n",
    "#         plot_dict['val_losses'] = val_losses\n",
    "#         plot_dict['losses'] = losses\n",
    "#         plot_dict['acc'] = acc\n",
    "#         plot_dict['prec'] = prec\n",
    "#         plot_dict['rec'] = rec\n",
    "#         plot_dict['f1'] = f1\n",
    "\n",
    "#         if epoch == 1 or epoch == 3 or epoch == 5 or epoch%10 == 0:\n",
    "#             save_fig(dataset['source'], h_params['model_name'], epoch, plot_dict)\n",
    "#         plt.figure(figsize=(20, 3))\n",
    "#         plt.plot(outps[0,:,:].reshape(-1).to('cpu').detach().numpy(), label='out')\n",
    "#         plt.plot(labels[0,:,:].reshape(-1).to('cpu').detach().numpy(), label='label')\n",
    "#         plt.legend()\n",
    "#         plt.title('train output')\n",
    "#         plt.show()\n",
    "#         plt.figure(figsize=(20, 3))\n",
    "#         plt.plot(val_outps[0,:,:].reshape(-1).to('cpu').detach().numpy(), label='out')\n",
    "#         plt.plot(val_labels[0,:,:].reshape(-1).to('cpu').detach().numpy(), label='label')\n",
    "#         plt.legend()\n",
    "#         plt.title('valid output')\n",
    "#         plt.show()\n",
    "\n",
    "#     t1 = time.time()\n",
    "\n",
    "#     print('finished in {} seconds'.format(t1 - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'T/F_ratio': [0.5, 0.5],\n",
      " 'add_event_r': 0.6,\n",
      " 'add_gap_r': 0.2,\n",
      " 'add_noise_r': 0.5,\n",
      " 'augmentation': True,\n",
      " 'batch_size': 36,\n",
      " 'condition': 'M>3',\n",
      " 'config_name': 'W6000_M>3_balance',\n",
      " 'drop_channel_r': 0.5,\n",
      " 'embed_size': 512,\n",
      " 'epochs': 100,\n",
      " 'file_name': 'STEAD_W6000_M>3_balance_dump.pkl',\n",
      " 'hidden_size': 512,\n",
      " 'imbalance': False,\n",
      " 'inp_size': 1000,\n",
      " 'input_dimention': (6000, 3),\n",
      " 'kernel_size': 10,\n",
      " 'label_type': 'gaussian',\n",
      " 'lr': 0.001,\n",
      " 'lstm_cell_count': 6,\n",
      " 'mode': 'generator',\n",
      " 'model_name': 'C-LSTM_W6000_M>3_balance',\n",
      " 'normalization_mode': 'std',\n",
      " 'outp_size': 6000,\n",
      " 'output_name': 'test_trainer',\n",
      " 'pre_emphasis': False,\n",
      " 'scale_amplitude_r': None,\n",
      " 'shift_event_r': 0.9,\n",
      " 'shuffle': True,\n",
      " 'source': 'STEAD',\n",
      " 'total_data_size': 20000,\n",
      " 'train_valid_test_split': [0.6, 0.2, 0.2],\n",
      " 'window_count': 6000}\n",
      "\u001b[32mEarthquake \u001b[37mpreprocessing multiprocess excute!!!\n",
      "\u001b[32mtrain \u001b[37m\n",
      "0% complete\n",
      "1% complete\n",
      "2% complete\n",
      "3% complete\n",
      "4% complete\n",
      "5% complete\n",
      "6% complete\n",
      "7% complete\n",
      "8% complete\n",
      "9% complete\n",
      "10% complete\n",
      "11% complete\n",
      "12% complete\n",
      "13% complete\n",
      "14% complete\n",
      "15% complete\n",
      "16% complete\n",
      "17% complete\n",
      "18% complete\n",
      "19% complete\n",
      "20% complete\n",
      "21% complete\n",
      "22% complete\n",
      "23% complete\n",
      "24% complete\n",
      "25% complete\n",
      "26% complete\n",
      "27% complete\n",
      "28% complete\n",
      "29% complete\n",
      "30% complete\n",
      "31% complete\n",
      "32% complete\n",
      "33% complete\n",
      "34% complete\n",
      "35% complete\n",
      "36% complete\n",
      "37% complete\n",
      "38% complete\n",
      "39% complete\n",
      "40% complete\n",
      "41% complete\n",
      "42% complete\n",
      "43% complete\n",
      "44% complete\n",
      "45% complete\n",
      "46% complete\n",
      "47% complete\n",
      "48% complete\n",
      "49% complete\n",
      "50% complete\n",
      "51% complete\n",
      "52% complete\n",
      "53% complete\n",
      "54% complete\n",
      "55% complete\n",
      "56% complete\n",
      "57% complete\n",
      "58% complete\n",
      "59% complete\n",
      "60% complete\n",
      "61% complete\n",
      "62% complete\n",
      "63% complete\n",
      "64% complete\n",
      "65% complete\n",
      "66% complete\n",
      "67% complete\n",
      "68% complete\n",
      "69% complete\n",
      "70% complete\n",
      "71% complete\n",
      "72% complete\n",
      "73% complete\n",
      "74% complete\n",
      "75% complete\n",
      "76% complete\n",
      "77% complete\n",
      "78% complete\n",
      "79% complete\n",
      "80% complete\n",
      "81% complete\n",
      "82% complete\n",
      "83% complete\n",
      "84% complete\n",
      "85% complete\n",
      "86% complete\n",
      "87% complete\n",
      "88% complete\n",
      "89% complete\n",
      "90% complete\n",
      "91% complete\n",
      "92% complete\n",
      "93% complete\n",
      "94% complete\n",
      "95% complete\n",
      "96% complete\n",
      "97% complete\n",
      "98% complete\n",
      "99% complete\n",
      "100% complete\n",
      "\u001b[32mvalidation \u001b[37m\n",
      "0% complete\n",
      "1% complete\n",
      "2% complete\n",
      "3% complete\n",
      "4% complete\n",
      "5% complete\n",
      "6% complete\n",
      "7% complete\n",
      "8% complete\n",
      "9% complete\n",
      "10% complete\n",
      "11% complete\n",
      "12% complete\n",
      "13% complete\n",
      "14% complete\n",
      "15% complete\n",
      "16% complete\n",
      "17% complete\n",
      "18% complete\n",
      "19% complete\n",
      "20% complete\n",
      "21% complete\n",
      "22% complete\n",
      "23% complete\n",
      "24% complete\n",
      "25% complete\n",
      "26% complete\n",
      "27% complete\n",
      "28% complete\n",
      "29% complete\n",
      "30% complete\n",
      "31% complete\n",
      "32% complete\n",
      "33% complete\n",
      "34% complete\n",
      "35% complete\n",
      "36% complete\n",
      "37% complete\n",
      "38% complete\n",
      "39% complete\n",
      "40% complete\n",
      "41% complete\n",
      "42% complete\n",
      "43% complete\n",
      "44% complete\n",
      "45% complete\n",
      "46% complete\n",
      "47% complete\n",
      "48% complete\n",
      "49% complete\n",
      "50% complete\n",
      "51% complete\n",
      "52% complete\n",
      "53% complete\n",
      "54% complete\n",
      "55% complete\n",
      "56% complete\n",
      "57% complete\n",
      "58% complete\n",
      "59% complete\n",
      "60% complete\n",
      "61% complete\n",
      "62% complete\n",
      "63% complete\n",
      "64% complete\n",
      "65% complete\n",
      "66% complete\n",
      "67% complete\n",
      "68% complete\n",
      "69% complete\n",
      "70% complete\n",
      "71% complete\n",
      "72% complete\n",
      "73% complete\n",
      "74% complete\n",
      "75% complete\n",
      "76% complete\n",
      "77% complete\n",
      "78% complete\n",
      "79% complete\n",
      "80% complete\n",
      "81% complete\n",
      "82% complete\n",
      "83% complete\n",
      "84% complete\n",
      "85% complete\n",
      "86% complete\n",
      "87% complete\n",
      "88% complete\n",
      "89% complete\n",
      "90% complete\n",
      "91% complete\n",
      "92% complete\n",
      "93% complete\n",
      "94% complete\n",
      "95% complete\n",
      "96% complete\n",
      "97% complete\n",
      "98% complete\n",
      "99% complete\n",
      "100% complete\n",
      "train length : \u001b[31m 6000 \u001b[37m / valid length : \u001b[31m 4000 \u001b[37m\n",
      "\u001b[32mNoise \u001b[37mpreprocessing multiprocess excute!!!\n",
      "\u001b[32mtrain \u001b[37m\n",
      "0% complete\n",
      "1% complete\n",
      "2% complete\n",
      "3% complete\n",
      "4% complete\n",
      "5% complete\n",
      "6% complete\n",
      "7% complete\n",
      "8% complete\n",
      "9% complete\n",
      "10% complete\n",
      "11% complete\n",
      "12% complete\n",
      "13% complete\n",
      "14% complete\n",
      "15% complete\n",
      "16% complete\n",
      "17% complete\n",
      "18% complete\n",
      "19% complete\n",
      "20% complete\n",
      "21% complete\n",
      "22% complete\n",
      "23% complete\n",
      "24% complete\n",
      "25% complete\n",
      "26% complete\n",
      "27% complete\n",
      "28% complete\n",
      "29% complete\n",
      "30% complete\n",
      "31% complete\n",
      "32% complete\n",
      "33% complete\n",
      "34% complete\n",
      "35% complete\n",
      "36% complete\n",
      "37% complete\n",
      "38% complete\n",
      "39% complete\n",
      "40% complete\n",
      "41% complete\n",
      "42% complete\n",
      "43% complete\n",
      "44% complete\n",
      "45% complete\n",
      "46% complete\n",
      "47% complete\n",
      "48% complete\n",
      "49% complete\n",
      "50% complete\n",
      "51% complete\n",
      "52% complete\n",
      "53% complete\n",
      "54% complete\n",
      "55% complete\n",
      "56% complete\n",
      "57% complete\n",
      "58% complete\n",
      "59% complete\n",
      "60% complete\n",
      "61% complete\n",
      "62% complete\n",
      "63% complete\n",
      "64% complete\n",
      "65% complete\n",
      "66% complete\n",
      "67% complete\n",
      "68% complete\n",
      "69% complete\n",
      "70% complete\n",
      "71% complete\n",
      "72% complete\n",
      "73% complete\n",
      "74% complete\n",
      "75% complete\n",
      "76% complete\n",
      "77% complete\n",
      "78% complete\n",
      "79% complete\n",
      "80% complete\n",
      "81% complete\n",
      "82% complete\n",
      "83% complete\n",
      "84% complete\n",
      "85% complete\n",
      "86% complete\n",
      "87% complete\n",
      "88% complete\n",
      "89% complete\n",
      "90% complete\n",
      "91% complete\n",
      "92% complete\n",
      "93% complete\n",
      "94% complete\n",
      "95% complete\n",
      "96% complete\n",
      "97% complete\n",
      "98% complete\n",
      "99% complete\n",
      "100% complete\n",
      "\u001b[32mvalidation \u001b[37m\n",
      "0% complete\n",
      "1% complete\n",
      "2% complete\n",
      "3% complete\n",
      "4% complete\n",
      "5% complete\n",
      "6% complete\n",
      "7% complete\n",
      "8% complete\n",
      "9% complete\n",
      "10% complete\n",
      "11% complete\n",
      "12% complete\n",
      "13% complete\n",
      "14% complete\n",
      "15% complete\n",
      "16% complete\n",
      "17% complete\n",
      "18% complete\n",
      "19% complete\n",
      "20% complete\n",
      "21% complete\n",
      "22% complete\n",
      "23% complete\n",
      "24% complete\n",
      "25% complete\n",
      "26% complete\n",
      "27% complete\n",
      "28% complete\n",
      "29% complete\n",
      "30% complete\n",
      "31% complete\n",
      "32% complete\n",
      "33% complete\n",
      "34% complete\n",
      "35% complete\n",
      "36% complete\n",
      "37% complete\n",
      "38% complete\n",
      "39% complete\n",
      "40% complete\n",
      "41% complete\n",
      "42% complete\n",
      "43% complete\n",
      "44% complete\n",
      "45% complete\n",
      "46% complete\n",
      "47% complete\n",
      "48% complete\n",
      "49% complete\n",
      "50% complete\n",
      "51% complete\n",
      "52% complete\n",
      "53% complete\n",
      "54% complete\n",
      "55% complete\n",
      "56% complete\n",
      "57% complete\n",
      "58% complete\n",
      "59% complete\n",
      "60% complete\n",
      "61% complete\n",
      "62% complete\n",
      "63% complete\n",
      "64% complete\n",
      "65% complete\n",
      "66% complete\n",
      "67% complete\n",
      "68% complete\n",
      "69% complete\n",
      "70% complete\n",
      "71% complete\n",
      "72% complete\n",
      "73% complete\n",
      "74% complete\n",
      "75% complete\n",
      "76% complete\n",
      "77% complete\n",
      "78% complete\n",
      "79% complete\n",
      "80% complete\n",
      "81% complete\n",
      "82% complete\n",
      "83% complete\n",
      "84% complete\n",
      "85% complete\n",
      "86% complete\n",
      "87% complete\n",
      "88% complete\n",
      "89% complete\n",
      "90% complete\n",
      "91% complete\n",
      "92% complete\n",
      "93% complete\n",
      "94% complete\n",
      "95% complete\n",
      "96% complete\n",
      "97% complete\n",
      "98% complete\n",
      "99% complete\n",
      "100% complete\n",
      "train length : \u001b[31m 6000 \u001b[37m / valid length : \u001b[31m 4000 \u001b[37m\n"
     ]
    }
   ],
   "source": [
    "from _preprocessing import *\n",
    "import pprint\n",
    "\n",
    "params = dict()\n",
    "\n",
    "# ------------------ configuration ------------------\n",
    "\n",
    "params['source']                 = 'STEAD'\n",
    "params['mode']                   = 'generator'\n",
    "params['window_count']           = 6000\n",
    "params['imbalance']              = False\n",
    "params['condition']              = 'M>3'\n",
    "params['config_name']            = make_config(params)\n",
    "params['file_name']              = params['source'] + '_' + params['config_name'] + '_dump.pkl'\n",
    "params['model_name']             = 'C-LSTM_' + params['config_name']\n",
    "\n",
    "# ------------------ preprocessing ------------------\n",
    "\n",
    "params['output_name']            = 'test_trainer'\n",
    "params['input_dimention']        = (6000, 3)\n",
    "params['shuffle']                = True\n",
    "params['label_type']             = 'gaussian'\n",
    "params['normalization_mode']     = 'std'\n",
    "params['augmentation']           = True\n",
    "params['add_event_r']            = 0.6\n",
    "params['add_gap_r']              = 0.2\n",
    "params['add_noise_r']            = 0.5\n",
    "params['drop_channel_r']         = 0.5\n",
    "params['shift_event_r']          = 0.9\n",
    "params['scale_amplitude_r']      = None\n",
    "params['pre_emphasis']           = False\n",
    "\n",
    "params['batch_size']             = 36\n",
    "params['total_data_size']        = 20000\n",
    "params['T/F_ratio']              = [0.5, 0.5]\n",
    "params['train_valid_test_split'] = [0.60, 0.20, 0.20]\n",
    "\n",
    "# ----------------- model-parameter -----------------\n",
    "\n",
    "params['kernel_size']            = 10\n",
    "params['lstm_cell_count']        = 6\n",
    "params['inp_size']               = params['window_count']//params['lstm_cell_count']\n",
    "params['embed_size']             = 512\n",
    "params['hidden_size']            = 512\n",
    "params['outp_size']              = 6000\n",
    "\n",
    "# ----------------- train-parameter -----------------\n",
    "\n",
    "params['epochs']                 = 100\n",
    "params['lr']                     = 0.001\n",
    "\n",
    "pprint.pprint(params)\n",
    "\n",
    "preprocessing_generator(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEVICE \t\t:  cuda:1\n",
      "pid \t\t:  30051\n",
      "\n",
      "---------------------------------Data---------------------------------\n",
      "\n",
      "file name \t: STEAD_W6000_M>3_balance_dump.pkl\n",
      "data length \t: 20000\n",
      "T/F count \t: 10000 / 10000\n",
      "T/F ratio \t: 50.0 %\n",
      "\n",
      "Train size \t: 12000\n",
      "Valid size \t: 4000\n",
      "Test size \t: 4000\n",
      "\n",
      "\n",
      "------------------------------Data Loader------------------------------\n",
      "\n",
      "X_train shape:  torch.Size([500, 3, 6000])  \ttype :  torch.DoubleTensor\n",
      "y_train shape:  torch.Size([500, 1, 6000])  \ttype :  torch.FloatTensor\n"
     ]
    }
   ],
   "source": [
    "from _utils import *\n",
    "dataset = load_dataset(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os, sys, time\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "DEVICE = torch.device('cuda:1' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "\n",
    "def save_fig(source, model_name, epoch, plot_dict):\n",
    "    DIR = os.getcwd()\n",
    "    output_dir = os.path.join(DIR, 'outputs', source, model_name)\n",
    "    \n",
    "    if not os.path.isdir(output_dir):\n",
    "        os.mkdir(output_dir)\n",
    "        \n",
    "    plt.figure(figsize=(10, 5))\n",
    "    try:\n",
    "        plt.plot(plot_dict['losses'][100:])\n",
    "        plt.plot(plot_dict['val_losses'][100:])\n",
    "    except:\n",
    "        pass\n",
    "    plt.legend(['train', 'validation'], loc='upper right')\n",
    "    plt.savefig(os.path.join(output_dir, model_name + '_' + str(epoch).zfill(4) + '_loss.png'))\n",
    "    plt.close()\n",
    "    \n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(plot_dict['acc'])\n",
    "    plt.plot(plot_dict['prec'])\n",
    "    plt.plot(plot_dict['rec'])\n",
    "    plt.plot(plot_dict['f1'])\n",
    "    plt.legend(['val_accuracy', 'val_precision', 'val_recall', 'val_F1_score'], loc='lower right')\n",
    "    plt.savefig(os.path.join(output_dir, model_name + '_' + str(epoch).zfill(4) + '_metric.png'))\n",
    "    plt.close()\n",
    "\n",
    "def weighted_BCE(output, target, weights=None):\n",
    "    output = torch.clamp(output,min=1e-7,max=1-1e-7)\n",
    "    bce = - weights[1] * target * torch.log(output) - (1 - target) * weights[0] * torch.log(1 - output)\n",
    "    return torch.mean(bce)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNEncoder(nn.Module):\n",
    "    def __init__(self, h_params):\n",
    "        super(CNNEncoder, self).__init__()\n",
    "\n",
    "        self.inp_size = h_params['inp_size']\n",
    "        self.inp_size = 6000\n",
    "        self.kernel_size = h_params['kernel_size']\n",
    "        self.embed_size = h_params['embed_size']*h_params['lstm_cell_count']\n",
    "#         self.embed_size = h_params['embed_size']\n",
    "\n",
    "        self.conv1 = nn.Conv1d(3, 4, kernel_size=self.kernel_size, padding=self.kernel_size//2)\n",
    "        self.maxpool1 = nn.MaxPool1d(kernel_size=2, stride=2)\n",
    "        self.conv2 = nn.Conv1d(4, 8, kernel_size=(self.kernel_size-2), padding=(self.kernel_size-2)//2)\n",
    "        self.maxpool2 = nn.MaxPool1d(kernel_size=2, stride=2)\n",
    "        self.conv3 = nn.Conv1d(8, 16, kernel_size=(self.kernel_size-4), padding=(self.kernel_size-4)//2)\n",
    "        self.maxpool3 = nn.MaxPool1d(kernel_size=2, stride=2)\n",
    "        self.conv4 = nn.Conv1d(16, 32, kernel_size=(self.kernel_size-6), padding=(self.kernel_size-6)//2)\n",
    "        self.maxpool4 = nn.MaxPool1d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(p=0.5)\n",
    "        self.embed1 = nn.Conv1d(32, 1, kernel_size=(self.kernel_size-6), padding=(self.kernel_size-6)//2)\n",
    "        self.embed2 = nn.Linear(in_features=(self.inp_size//16+1), out_features=self.embed_size)\n",
    "        self.embed = nn.Linear(in_features=32 * (self.inp_size//16), out_features=self.embed_size)\n",
    "\n",
    "        self.softmax = nn.Softmax()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, inp):\n",
    "        inp = inp.to(DEVICE, dtype=torch.float)\n",
    "        out = self.conv1(inp)\n",
    "        out = self.relu(out)\n",
    "        out = self.dropout(out)\n",
    "        out = self.maxpool1(out)\n",
    "\n",
    "#         out = self.conv2(out)\n",
    "#         out = self.relu(out)\n",
    "#         out = self.dropout(out)\n",
    "#         out = self.maxpool2(out)\n",
    "\n",
    "#         out = self.conv3(out)\n",
    "#         out = self.relu(out)\n",
    "#         out = self.dropout(out)\n",
    "#         out = self.maxpool3(out)\n",
    "\n",
    "#         out = self.conv4(out)\n",
    "#         out = self.relu(out)\n",
    "#         out = self.dropout(out)\n",
    "#         out = self.maxpool4(out)\n",
    "                \n",
    "#         out = out.view(-1, 32 * (self.inp_size//16))\n",
    "#         out = self.embed(out)\n",
    "        out = self.embed1(out)\n",
    "        out = out.view(-1, 376)\n",
    "        \n",
    "        out = self.embed2(out)\n",
    "        \n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class RNNDecoder(nn.Module):\n",
    "    def __init__(self, h_params):\n",
    "        super(RNNDecoder, self).__init__()\n",
    "\n",
    "        self.cell_count = h_params['lstm_cell_count']\n",
    "        self.embed_size = h_params['embed_size']\n",
    "        self.hidden_size = h_params['hidden_size']\n",
    "        \n",
    "        self.lstm_cell = nn.LSTMCell(input_size = self.embed_size, hidden_size = self.hidden_size)\n",
    "        self.fc_out = nn.Linear(in_features = self.hidden_size, out_features=16*100)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, inp_emb):\n",
    "        batch_size = inp_emb.size(0)\n",
    "\n",
    "        window_count = 100 * self.cell_count\n",
    "\n",
    "        hidden_state = torch.zeros((batch_size, self.hidden_size)).to(DEVICE)\n",
    "        cell_state = torch.zeros((batch_size, self.hidden_size)).to(DEVICE)\n",
    "\n",
    "        outs = torch.empty((batch_size, 16, window_count))\n",
    "\n",
    "        for idx in range(self.cell_count):\n",
    "            hidden_state, cell_state = self.lstm_cell(inp_emb[:, idx*512:(idx+1)*512], (hidden_state, cell_state))\n",
    "            \n",
    "            if idx == self.cell_count-1:\n",
    "                outs = self.fc_out(hidden_state)\n",
    "#             out = self.sigmoid(out)\n",
    "\n",
    "#             outs[:, :, idx*100:(idx+1)*100] = out.reshape(500,16,-1)[:,:,:]\n",
    "    \n",
    "        return outs.reshape(500, 16, -1)\n",
    "\n",
    "\n",
    "class CNNDecoder(nn.Module):\n",
    "    def __init__(self, h_params):\n",
    "        super(CNNDecoder, self).__init__()\n",
    "\n",
    "        self.kernel_size = h_params['kernel_size']\n",
    "        self.outp_size = h_params['outp_size']\n",
    "        \n",
    "        self.Upsample1 = nn.Upsample(size=self.outp_size//8)\n",
    "        self.conv1 = nn.Conv1d(16, 8, kernel_size=self.kernel_size-1, padding=self.kernel_size//2-1)\n",
    "            \n",
    "        self.Upsample2 = nn.Upsample(size=self.outp_size//4)\n",
    "        self.conv2 = nn.Conv1d(8, 4, kernel_size=self.kernel_size-1, padding=self.kernel_size//2-1)\n",
    "            \n",
    "        self.Upsample3 = nn.Upsample(size=self.outp_size//2)\n",
    "        self.conv3 = nn.Conv1d(4, 2, kernel_size=self.kernel_size-1, padding=self.kernel_size//2-1)\n",
    "            \n",
    "        self.Upsample4 = nn.Upsample(size=self.outp_size)\n",
    "        self.conv4 = nn.Conv1d(2, 1, kernel_size=self.kernel_size-1, padding=self.kernel_size//2-1)\n",
    "                \n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(p=0.9)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, inp):\n",
    "\n",
    "        inp = inp.to(DEVICE, dtype=torch.float)\n",
    "        \n",
    "        out = self.Upsample1(inp)\n",
    "        out = self.conv1(out)\n",
    "#         out = self.relu(out)\n",
    "#         out = self.dropout(out)\n",
    "        \n",
    "        out = self.Upsample2(out)\n",
    "        out = self.conv2(out)\n",
    "#         out = self.relu(out)\n",
    "#         out = self.dropout(out)\n",
    "        \n",
    "        out = self.Upsample3(out)\n",
    "        out = self.conv3(out)\n",
    "#         out = self.relu(out)\n",
    "#         out = self.dropout(out)\n",
    "        \n",
    "        out = self.Upsample4(out)\n",
    "        out = self.conv4(out)\n",
    "#         out = self.relu(out)\n",
    "#         out = self.dropout(out)\n",
    "        \n",
    "    \n",
    "        out = self.sigmoid(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "    \n",
    "class C_LSTM(nn.Module):\n",
    "    def __init__(self, h_params):\n",
    "        super(C_LSTM, self).__init__()\n",
    "        \n",
    "        self.cell_count = h_params['lstm_cell_count']\n",
    "        self.inp_size = h_params['inp_size']\n",
    "        self.kernel_size = h_params['kernel_size']\n",
    "        \n",
    "#         self.cnn_encoder = list()\n",
    "#         for i in range(self.cell_count):\n",
    "#             self.cnn_encoder.append(CNNEncoder(h_params).to(DEVICE))\n",
    "        self.cnn_encoder = CNNEncoder(h_params).to(DEVICE)\n",
    "        self.lstm_decoder = RNNDecoder(h_params).to(DEVICE)\n",
    "        self.cnn_decoder = CNNDecoder(h_params).to(DEVICE)\n",
    "        self.h_params = h_params\n",
    "\n",
    "    def forward(self, inps):\n",
    "        '''CNN-Encoder'''\n",
    "#         for i in range(self.cell_count):\n",
    "#             inp = inps[:,:,i*self.inp_size:(i+1)*self.inp_size]\n",
    "\n",
    "#             outp = self.cnn_encoder[i](inp)\n",
    "#             if i == 0:\n",
    "#                 outps = outp\n",
    "#             else:\n",
    "#                 outps = torch.cat((outps, outp), 1)\n",
    "                \n",
    "        outps = self.cnn_encoder(inps)\n",
    "        cnn_embedding = outps.to(DEVICE)\n",
    "        \n",
    "        '''LSTM-Decoder'''\n",
    "        lstm_embedding = self.lstm_decoder(cnn_embedding).to(DEVICE)\n",
    "\n",
    "        '''CNN-Decoder'''\n",
    "#         for i in range(self.h_params['lstm_cell_count']):\n",
    "#             outp = self.cnn_decoder(lstm_embedding[:,:,i*100:(i+1)*100]).to(DEVICE)\n",
    "#             if i == 0:\n",
    "#                 outps = outp\n",
    "#             else:\n",
    "#                 outps = torch.cat((outps, outp), 2)\n",
    "        \n",
    "        outps = self.cnn_decoder(lstm_embedding[:,:,:]).to(DEVICE)\n",
    "            \n",
    "        return outps\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataset, h_params):\n",
    "    \n",
    "    epochs = h_params['epochs']\n",
    "    batch_size = dataset['batch_size']\n",
    "    total_step = dataset['train_size']//batch_size\n",
    "    \n",
    "    c_lstm = C_LSTM(h_params)\n",
    "    \n",
    "    params = list(c_lstm.parameters())\n",
    "    optimizer = torch.optim.Adam(params, lr=h_params['lr'])\n",
    "\n",
    "    plot_dict = dict()\n",
    "    losses = list()\n",
    "    val_losses = list()\n",
    "    acc = list()\n",
    "    prec = list() \n",
    "    rec = list()\n",
    "    f1 = list()\n",
    "\n",
    "    t0 = time.time()\n",
    "    \n",
    "    for epoch in range(1, epochs+1):\n",
    "\n",
    "        for i_step in range(1, total_step+1):\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            c_lstm.train()\n",
    "\n",
    "            inps, labels = next(iter(dataset['train_loader']))\n",
    "            \n",
    "            outps = c_lstm(inps)\n",
    "            labels = labels.to(DEVICE)\n",
    "            \n",
    "            loss = weighted_BCE(outps[:,:,:], labels[:,:,:], weights=weights)\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # - - - Validate - - -\n",
    "            with torch.no_grad():\n",
    "\n",
    "                c_lstm.eval()\n",
    "\n",
    "                val_inps, val_labels = next(iter(dataset['valid_loader']))\n",
    "\n",
    "                val_outps = c_lstm(val_inps)\n",
    "                val_labels = val_labels.to(DEVICE)\n",
    "\n",
    "                val_loss = weighted_BCE(val_outps[:,:,:], val_labels[:,:,:], weights=weights)\n",
    "\n",
    "                val_accuracy, val_precision, val_recall, val_F1_score, TP, FP, TN, FN = 0, 0, 0, 0, 0, 0, 0, 0\n",
    "    #                 val_accuracy, val_precision, val_recall, val_F1_score, TP, FP, TN, FN = metric(val_outps, val_labels)\n",
    "                \n",
    "            val_losses.append(val_loss.item())\n",
    "            losses.append(loss.item())\n",
    "            acc.append(val_accuracy)\n",
    "            prec.append(val_precision)\n",
    "            rec.append(val_recall)\n",
    "            f1.append(val_F1_score)\n",
    "            \n",
    "            stats_loss = 'Epoch [%d/%d], Step [%d/%d], Loss: %.4f, Val Loss: %.4f, ' % \\\n",
    "                        (epoch, epochs, i_step, total_step, loss.item(), val_loss.item())\n",
    "            stats_metric = 'accuracy : %.4f, precision : %.4f, recall : %.4f, F1_score : %.4f, ' % \\\n",
    "                            (val_accuracy, val_precision, val_recall, val_F1_score)\n",
    "            stats_conf = 'TP : %d, FP : %d, TN : %d, FN : %d' % (TP, FP, TN, FN)\n",
    "            stats = stats_loss + stats_metric + stats_conf\n",
    "#             print('\\r', stats, end=\"\")\n",
    "            print('\\r', stats_loss, end=\"\")\n",
    "\n",
    "#         print('\\r', stats)\n",
    "        print('\\r', stats_loss)\n",
    "\n",
    "        plot_dict['val_losses'] = val_losses\n",
    "        plot_dict['losses'] = losses\n",
    "        plot_dict['acc'] = acc\n",
    "        plot_dict['prec'] = prec\n",
    "        plot_dict['rec'] = rec\n",
    "        plot_dict['f1'] = f1\n",
    "\n",
    "        if epoch == 1 or epoch == 3 or epoch == 5 or epoch%10 == 0:\n",
    "            save_fig(dataset['source'], h_params['model_name'], epoch, plot_dict)\n",
    "#         plt.figure(figsize=(20, 3))\n",
    "#         plt.plot(outps[0,:,:].reshape(-1).to('cpu').detach().numpy(), label='out')\n",
    "#         plt.plot(labels[0,:,:].reshape(-1).to('cpu').detach().numpy(), label='label')\n",
    "#         plt.legend()\n",
    "#         plt.ylim(0, 1)\n",
    "#         plt.title('train output')\n",
    "#         plt.show()\n",
    "        plt.figure(figsize=(20, 3))\n",
    "        plt.plot(val_inps[0,0,:].reshape(-1).to('cpu').detach().numpy(), label='out')\n",
    "        plt.legend()\n",
    "#         plt.ylim(0, 1)\n",
    "        plt.title('valid input')\n",
    "        plt.show()\n",
    "        plt.figure(figsize=(20, 3))\n",
    "        plt.plot(val_outps[0,:,:].reshape(-1).to('cpu').detach().numpy(), label='out')\n",
    "        plt.plot(val_labels[0,:,:].reshape(-1).to('cpu').detach().numpy(), label='label')\n",
    "        plt.legend()\n",
    "        plt.ylim(0, 1)\n",
    "        plt.title('valid output')\n",
    "        plt.show()\n",
    "\n",
    "    t1 = time.time()\n",
    "\n",
    "    print('finished in {} seconds'.format(t1 - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Given groups=1, weight of size [1, 32, 4], expected input[500, 4, 3000] to have 32 channels, but got 4 channels instead",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-bbf6c6a29113>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# from _C_LSTM_Picker import *\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mweights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m12000\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-8-b62514da210f>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(dataset, h_params)\u001b[0m\n\u001b[1;32m     29\u001b[0m             \u001b[0minps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train_loader'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m             \u001b[0moutps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mc_lstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m             \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-5148211f1689>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inps)\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[0;31m#                 outps = torch.cat((outps, outp), 1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 176\u001b[0;31m         \u001b[0moutps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcnn_encoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    177\u001b[0m         \u001b[0mcnn_embedding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutps\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-5148211f1689>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inp)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;31m#         out = out.view(-1, 32 * (self.inp_size//16))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;31m#         out = self.embed(out)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m376\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    261\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 263\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    258\u001b[0m                             _single(0), self.dilation, self.groups)\n\u001b[1;32m    259\u001b[0m         return F.conv1d(input, weight, bias, self.stride,\n\u001b[0;32m--> 260\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    261\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Given groups=1, weight of size [1, 32, 4], expected input[500, 4, 3000] to have 32 channels, but got 4 channels instead"
     ]
    }
   ],
   "source": [
    "# from _C_LSTM_Picker import *\n",
    "weights = [1, 12000]\n",
    "train(dataset, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
